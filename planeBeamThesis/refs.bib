@misc{Svoice,
  doi = {10.48550/ARXIV.2003.01531},
  
  url = {https://arxiv.org/abs/2003.01531},
  
  author = {Nachmani, E. and Adi, Y. and Wolf, L.},
  
  keywords = {Audio and Speech Processing (eess.AS), Machine Learning (cs.LG), Sound (cs.SD), Machine Learning (stat.ML), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Voice Separation with an Unknown Number of Multiple Speakers},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@InProceedings{Cherry,
  author = 	 "Cherry, E.C.",
  title =        "Some experiments on the recognition of speech, with one and with two ears",
  booktitle =  "Journal of the Acoustical Society of America",
  year = 	 "1953",
  volume = 	 "25",
  pages = 	 "975â€“979"
}

@misc{SupervisedSpeechSeparationBasedonDeepLearning,
  doi = {10.48550/ARXIV.1708.07524},
  
  url = {https://arxiv.org/abs/1708.07524},
  
  author = {Wang, D. and Chen, J.},
  
  keywords = {Computation and Language (cs.CL), Machine Learning (cs.LG), Neural and Evolutionary Computing (cs.NE), Sound (cs.SD), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Supervised Speech Separation Based on Deep Learning: An Overview},
  
  publisher = {arXiv},
  
  year = {2017},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{DPRNN,
  doi = {10.48550/ARXIV.1910.06379},
  
  url = {https://arxiv.org/abs/1910.06379},
  
  author = {Luo, Y. and Chen, Z. and Yoshioka, T.},
  
  keywords = {Audio and Speech Processing (eess.AS), Machine Learning (cs.LG), Sound (cs.SD), FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Dual-path RNN: efficient long sequence modeling for time-domain single-channel speech separation},
  
  publisher = {arXiv},
  
  year = {2019},
  
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}


@article{stoller2018wave,
  title={Wave-u-net: A multi-scale neural network for end-to-end audio source separation},
  author={Stoller, D. and Ewert, S. and Dixon, S.},
  journal={arXiv preprint arXiv:1806.03185},
  year={2018}
}

@inproceedings{luo2018tasnet,
  title={Tasnet: time-domain audio separation network for real-time, single-channel speech separation},
  author={Luo, Y. and Mesgarani, N.},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={696--700},
  year={2018},
  organization={IEEE}
}

@article{luo2019conv,
  title={Conv-tasnet: Surpassing ideal time--frequency magnitude masking for speech separation},
  author={Luo, Y. and Mesgarani, N.},
  journal={IEEE/ACM transactions on audio, speech, and language processing},
  volume={27},
  number={8},
  pages={1256--1266},
  year={2019},
  publisher={IEEE}
}

@article{bahmaninezhad2019comprehensive,
  title={A comprehensive study of speech separation: spectrogram vs waveform separation},
  author={Bahmaninezhad, F. and Wu, J. and Gu, R. and Zhang, S. and Xu, Y. and Yu, M. and Yu, D.},
  journal={arXiv preprint arXiv:1905.07497},
  year={2019}
}

@inproceedings{li2018independently,
  title={Independently recurrent neural network (indrnn): Building a longer and deeper rnn},
  author={Li, S. and Li, W. and Cook, C. and Zhu, C. and Gao, Y.},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={5457--5466},
  year={2018}
}


@article{bai2018empirical,
  title={An empirical evaluation of generic convolutional and recurrent networks for sequence modeling},
  author={Bai, S. and Kolter, Z. and Koltun, V.},
  journal={arXiv preprint arXiv:1803.01271},
  year={2018}
}

@inproceedings{liu2020deep,
  title={Deep CASA for talker-independent monaural speech separation},
  author={Liu, Y. and Delfarah, M. and Wang, D.},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={6354--6358},
  year={2020},
  organization={IEEE}
}

@article{ma2020two,
  title={Two-stage model and optimal SI-SNR for monaural multi-speaker speech separation in noisy environment},
  author={Ma, C. and Li, D. and Jia, X.},
  journal={arXiv preprint arXiv:2004.06332},
  year={2020}
}

@article{vanishing,
  title={The vanishing gradient problem during learning recurrent neural nets and problem solutions},
  author={Hochreiter, S.},
  journal={International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume={6},
  number={02},
  pages={107--116},
  year={1998},
  publisher={World Scientific}
}

@article{exploding,
  title={The exploding gradient problem demystified-definition, prevalence, impact, origin, tradeoffs, and solutions},
  author={Philipp, G. and Song, D. and Carbonell, J.},
  journal={arXiv preprint arXiv:1712.05577},
  year={2017}
}

@article{cosentino2020librimix,
  title={Librimix: An open-source dataset for generalizable speech separation},
  author={Cosentino, J. and Pariente, M. and Cornell, S. and Deleforge, A. and Vincent, E.},
  journal={arXiv preprint arXiv:2005.11262},
  year={2020}
}

@article{MS-SNSD,
  title={A scalable noisy speech dataset and online subjective test framework},
  author={Reddy, C. and Beyrami, E. and Pool, J. and Cutler, R. and Srinivasan, S. and Gehrke, J.},
  journal={arXiv preprint arXiv:1909.08050},
  year={2019}
}

@article{pariente2020asteroid,
  title={Asteroid: the PyTorch-based audio source separation toolkit for researchers},
  author={Pariente, M. and Cornell, S. and Cosentino, J. and Sivasankaran, S. and Tzinis, E. and Heitkaemper, J. and Olvera, M. and St{\"o}ter, F. and Hu, M. and Mart{\'\i}n-Do{\~n}as, J.},
  journal={arXiv preprint arXiv:2005.04132},
  year={2020}
}

@article{WHAM,
  author    = {Wichern, G. and
               Antognini, J. and
               Flynn, M. and
            Zhu, L. and
            McQuinn, E. and
               Crow, D. and
               Manilow, M. and
               Le Roux, J.},
  title     = {WHAM!: Extending Speech Separation to Noisy Environments},
  journal   = {CoRR},
  volume    = {abs/1907.01160},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.01160},
  eprinttype = {arXiv},
  eprint    = {1907.01160},
  timestamp = {Mon, 08 Jul 2019 14:12:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1907-01160.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kolbaek2017multitalker,
  title={Multitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks},
  author={Kolb{\ae}k, M. and Yu, D. and Tan, Z. and Jensen, J.},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={25},
  number={10},
  pages={1901--1913},
  year={2017},
  publisher={IEEE}
}

@article{simonyan2014very,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, K. and Zisserman, A.},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}